---
title: englisten
date: 2020-06-20 18:53:54
---


## 这是什么

英语听力解析系统是英语教学及学习的辅助小工具，作为 Snawedu 系列的首个完整版（其它都还只是半成品），它具有分析英语听力音频并进行裁剪的效果，使用了语音识别以及自己研究的算法，1.0.0 版本中的设置是经历多次试验和筛选留下的成功率极高的一种设置。当然，在音频文件的格式要求上，实际并没有多大要求，导入的对话框所限制的不过是常用的几个格式，因为使用了 ffmpeg，所以，理论上 ffmpeg 支持的格式本解析系统都支持。

## 如何开发的 ？

本应用使用 electron+python 混合开发，nsis 进行打包，基于 socket 通信采用了前后端分离的设计

## 有什么特点

1. 基于 ffmpeg，支持格式多
2. 主题多样，点击右下角按钮一键换装
3. 设置详细

## 使用要求

1. 本程序要求 Windows7 64bit 及以上操作系统，mac 和 Linux 等其它平台需要自行编译
2. 计算机资源足够（由于使用了人工智能技术）
3. 6777 与 6778 端口空闲
4. 不能同时运行多个程序
5. 设置中不能包含导致 json 格式错误的特殊字符

## 协议

本项目采用 SATA 协议 -https://github.com/zTrix/sata-license

```
你不知道这代表什么？简单来说，就是如果你使用了该程序，你需要表示感谢，接下来你便可以随意使用它。
```

当然，比赛期间不需要 star 之类的，SATA 协议将在本程序公开源代码后生效

## 快速开始

1. 首先进行安装

   ![1](https://dist.copur.xyz/images/englisten-01.png)

2. 安装完成后进入软件

   ![1](https://dist.copur.xyz/images/englisten-02.png)

3. 进入设置界面进行微调

   ![3](https://dist.copur.xyz/images/englisten-03.png)

4. 点击导入选择音频文件

   细节确认中的音频是指可能会被作为段落的音频，该功能在后期将实现自动化

   ![4](https://dist.copur.xyz/images/englisten-04.png)

5. 等待结束

   ![5](https://dist.copur.xyz/images/englisten-05.png)

6. 回到主界面，点击刚刚解析的音频进行导出

   ![6](https://dist.copur.xyz/images/englisten-06.png)

7. 导出完成后会显示导出文件夹

## 设置怎么调？

em,这就有点复杂了，需要先牵扯到程序的运算过程了

1. 首先，几个设置中排在第一位便是第一过滤系统，负责直接筛掉那些连时长也没有达到要求的片段，而该格的单位为 s，像默认设置中的 6 意味着时长小于 6s 的片段都会被删除，该功能主要用来过滤一些“ding~”，以及一些无意义的杂音。
2. 片段相似度临界为前后片段相似度的筛选临界值，当前后片段相似度超过该临界值时该片段将被舍弃，当然因为语音识别（在用户电脑跑的 AI）的能力问题无法把两段一模一样的音频识别完整而使用 100%作为临界值，所以，再进行多次试验之后而得出当前版本匹配 AI 的临界值应为 85%，当然，在后续测验中，发现 89%的值更适合，然而，既然已经打包完成，而且 85%的临界值的解析成功率也已经很高了，所以默认设置就保留了 85%的临界值。该格使用百分比，因此请不要使该格的数值超过 95%经测试，95%以上能过滤相似片段的能力几乎为 0.该功能主要用来过滤相似片段（即重复朗读的片段），当然，如果重复的片段是由不同的人朗读的话，临界值需要调整到 83%左右，不过，随着以后 AI 的强化，估计这种差异可以去除。
3. 接下来是简单介绍静音判断值和静音判断临界的区别，这两个是用来区别麦克风静音和电脑合成的静音，经过分析发现，电脑合成的静音一般振幅在 0~15 至今，当然也有部分静音是达到 18、19 的，因此，电脑合成的静音在默认设置中被设定为 20，而静音判断值是麦克风静音的临界值，由于麦克风静音时环境杂音的影响，麦克风空置无法达到电脑合成的静音效果，故设该参数。这两个参数的作用便是一切的基础，依靠静音将听力片段进行切割，从而进行后续的步骤。
4. 关键词列表便是该设置页面中最经常需要调整的地方了，不过，经过多次试验，默认设置中的关键词已经基本满足要求，关键词不是越多越好，因此，若不是特别需要请不要修改。修改关键词的方法是直接点击关键词对应标签的 x 从而删除该关键词，而点击关键词列表格子的空白处就可以新建新的标签，当然，如果是空白的标签便会直接被回收删除。
5. 试听过滤文本可以说是最不需要修改的一个了，毕竟这么多听力听下来，试听的文本基本是问你衬衫的价格，准备的试听过滤文本就不用修改了，当然，由于语音识别还不够智能的原因，所以默认设置中的过滤文本与我们所熟知的衬衫有所不同。
6. 接下来便是最重要的一点，那就是设置的保存问题，该设置全部使用自动保存，即所有设置都是在失去焦点后便会立即保存，保存成功后右上角就会弹出提示保存成功。
7. 皮肤应该也算设置的一种，只要点击更换皮肤便会自动保存。

## 其它平台编译

由于本系统使用 electron 和 python 构建，因此具有跨平台的功能

注意：开发者构建的 pydub 是修改过的版本，因此，按照该步骤编译的系统需要安装 ffmpeg

1. 安装 python 和 nodejs

2. ```
   pip install pydub
   pip install pyinstaller
   pip install speechrecognition
   pip install pocketsphinx
   ```

3. 如果缺少 pocketsphinx 的 wheel 需前往https://www.lfd.uci.edu/~gohlke/pythonlibs/下载安装

4. 安装 ffmpeg

5. 安装 pocketsphinx 的中文识别包

6. 执行`pyinstaller-F main.py`

   如果是 Windows，可以使用`pyinstaller --version-file=ver_info.txt -F -i logo.ico main.py`

7. 修改前端脚本 index.js 中启动后端的命令，并将编译好的后端放在正确位置

8. 执行`asar p ui app.asar`

9. 前往https://npm.taobao.org/mirrors/electron/下载目标系统的electron

10. 将 app.asar 放在 resource 目录下

11. 在 electron 根目录新建 data 和 logs 文件夹，将 set.json 移动到根目录

12. 至此，编译完成